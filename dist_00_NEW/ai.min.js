import * as webLlmSdk from 'https://esm.run/@mlc-ai/web-llm'

function initializeWebLlmContext(environment) {
  console.log('🧠 Loading AI (WebLLM) model...')
  if (!environment.webllm) {
    environment.webllm = {
      engine: null,
      isReady: false,
      initPromise: null,
      async init(modelIdentifier = 'Phi-3.5-mini-instruct-q4f16_1-MLC') {
        if (this.initPromise) {
          return this.initPromise
        }
        this.engine = new webLlmSdk.MLCEngine()
        this.initPromise = this.engine
          .reload(modelIdentifier, {
            temperature: 0.7,
            top_p: 0.9
          })
          .then(() => {
            this.isReady = true
            console.log('✅ [WebLLM] Model Ready.')
            return this.engine
          })
        return this.initPromise
      }
    }
    environment.webllm.init().catch((initializationError) => {
      console.error('❌ [WebLLM] Error al inicializar:', initializationError)
    })
  }
  return environment
}
const initializeAi = (environment) => {
  return initializeWebLlmContext(environment)
}
export { initializeAi as init }
